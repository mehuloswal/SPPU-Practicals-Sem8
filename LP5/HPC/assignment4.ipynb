{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLwiefGb-C4d",
        "outputId": "e35b765f-f595-45bd-abc8-f8faf7a942a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-yph6ykrv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-yph6ykrv\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ],
      "source": [
        "# Set up CUDA\n",
        "#First Change runtime to GPU and run this cell\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "#include <functional>\n",
        "#include <stdlib.h>     /* srand, rand */\n",
        "#include <time.h>       /* time */\n",
        "\n",
        "#define ROW_TILE_WIDTH 32\n",
        "#define COL_TILE_WIDTH 32\n",
        "\n",
        "template<typename T>\n",
        "__global__\n",
        "void naive_matrix_multiply(T *A, T *B, T* C, int width, int C_rows, int C_cols)\n",
        "{\n",
        "  int row = blockIdx.y * blockDim.y + threadIdx.y;   \n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  // check boundry conditions\n",
        "  if( row < C_rows && col < C_cols ){\n",
        "    // do the multiplication for one row and col\n",
        "    T value = 0;\n",
        "    for(int k = 0; k < width; k++){\n",
        "      value += A[row * width + k] * B[k * C_cols + col];\n",
        "    }\n",
        "    // store result\n",
        "    C[row * C_cols + col] = value;\n",
        "  }\n",
        "  \n",
        "\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void initialize_matrix(T* M, int rows, int cols, std::function<float()> F) {\n",
        "  for(int i = 0; i < rows; i++){\n",
        "    for(int j = 0; j < cols; j++){\n",
        "      M[i * cols + j] = F();\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "void naive_matrix_multiply_cpu(T *A, T *B, T* C, int width, int C_rows, int C_cols){\n",
        "  for(int i = 0; i < C_rows; i++)\n",
        "    for(int j = 0; j < C_cols; j++){\n",
        "      T value = 0.0f;\n",
        "      for(int k = 0; k < width; k++){\n",
        "        value += A[i * width + k] * B[k * C_cols + j];\n",
        "      }\n",
        "      C[i * C_cols + j] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "template<typename T>\n",
        "bool check_equal(T* A1, T* A2, int rows, int cols){\n",
        "  for(int i = 0; i < rows; i++)\n",
        "    for(int j = 0; j < cols; j++){\n",
        "      if(abs(A1[i * cols + j] - A2[i * cols + j]) > 0.00001){\n",
        "          return false;\n",
        "      }\n",
        "    }\n",
        "  \n",
        "  return true;\n",
        "}\n",
        "\n",
        "\n",
        "int main(void)\n",
        "{\n",
        "  int A_rows = 1 << 8;\n",
        "  int A_cols = 1 << 10;\n",
        "  int B_rows = A_cols;\n",
        "  int B_cols = 1 << 12;\n",
        "  int C_rows = A_rows;\n",
        "  int C_cols = B_cols;\n",
        "  int A_size = A_rows * A_cols;\n",
        "  int B_size = B_rows * B_cols;\n",
        "  int C_size = C_rows * C_cols;\n",
        "  float *A, *B, *C, *C_cpu;\n",
        "\n",
        "  // Allocate Unified Memory â€“ accessible from CPU or GPU\n",
        "  cudaMallocManaged(&A, A_size*sizeof(float));\n",
        "  cudaMallocManaged(&B, B_size*sizeof(float));\n",
        "  cudaMallocManaged(&C, C_size*sizeof(float));\n",
        "  cudaMallocManaged(&C_cpu, C_size*sizeof(float));\n",
        "\n",
        "  // initialize A and B matrices\n",
        "  auto all_ones = []() -> float {\n",
        "    return 1.0f;\n",
        "  };\n",
        "\n",
        "  srand (time(NULL));\n",
        "  auto rand_numbers = []() -> float {\n",
        "    auto f = static_cast<float>(rand())/(static_cast<float>(RAND_MAX/1000));\n",
        "    int n = static_cast<int>(f);\n",
        "    return static_cast<float>(n);\n",
        "  };\n",
        "\n",
        "  initialize_matrix<float>(A, A_rows, A_cols, rand_numbers);\n",
        "  initialize_matrix<float>(B, B_rows, B_cols, rand_numbers);\n",
        "\n",
        "  dim3 dim_grid(C_cols/COL_TILE_WIDTH, C_rows/ROW_TILE_WIDTH, 1);\n",
        "  dim3 dim_block(COL_TILE_WIDTH, ROW_TILE_WIDTH, 1);\n",
        "\n",
        "  naive_matrix_multiply<float><<<dim_grid, dim_block>>>(A, B, C, A_cols, C_rows, C_cols);\n",
        "\n",
        "  // Wait for GPU to finish before accessing on host\n",
        "  cudaDeviceSynchronize();\n",
        "  \n",
        "  // check results\n",
        "  naive_matrix_multiply_cpu<float>(A, B, C_cpu, A_cols, C_rows, C_cols);\n",
        "  \n",
        "  \n",
        "  if(check_equal<float>(C, C_cpu, C_rows, C_cols))\n",
        "    std::cout << \"PASS\" << std::endl;\n",
        "  else\n",
        "    std::cout << \"FAIL\" << std::endl;\n",
        "\n",
        "  // Free memory\n",
        "  cudaFree(A);\n",
        "  cudaFree(B);\n",
        "  cudaFree(C);\n",
        "  \n",
        "  return 0; \n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebqsk_UBG-be",
        "outputId": "3dfef37b-50a6-458c-c412-e323748f7ef8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASS\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
